{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ds = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(wine_ds, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data such as 60% as training set, 20% for each set the validation set and test set\n",
    "train, validate, test = np.split(df.sample(frac=1, random_state=42), [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) == len(train) + len(validate) + len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_label = train.iloc[:,:-1], train.iloc[:,-1:]\n",
    "validate_input, validate_label = validate.iloc[:,:-1], validate.iloc[:,-1:]\n",
    "test_input, test_label = test.iloc[:,:-1], test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape[1] == 11, train_label.shape[1] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>959.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.345255</td>\n",
       "      <td>0.525647</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>2.511470</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>15.786236</td>\n",
       "      <td>46.198123</td>\n",
       "      <td>0.996746</td>\n",
       "      <td>3.307581</td>\n",
       "      <td>0.654661</td>\n",
       "      <td>10.383125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.777409</td>\n",
       "      <td>0.181753</td>\n",
       "      <td>0.192162</td>\n",
       "      <td>1.421391</td>\n",
       "      <td>0.047510</td>\n",
       "      <td>10.423680</td>\n",
       "      <td>32.432648</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.157601</td>\n",
       "      <td>0.164917</td>\n",
       "      <td>1.065611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995540</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.996720</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.997870</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.600000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count     959.000000        959.000000   959.000000      959.000000   \n",
       "mean        8.345255          0.525647     0.270459        2.511470   \n",
       "std         1.777409          0.181753     0.192162        1.421391   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.100000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.300000          0.630000     0.420000        2.600000   \n",
       "max        15.600000          1.580000     0.790000       15.500000   \n",
       "\n",
       "        chlorides  free sulfur dioxide  total sulfur dioxide     density  \\\n",
       "count  959.000000           959.000000            959.000000  959.000000   \n",
       "mean     0.087281            15.786236             46.198123    0.996746   \n",
       "std      0.047510            10.423680             32.432648    0.001941   \n",
       "min      0.012000             1.000000              6.000000    0.990070   \n",
       "25%      0.070000             7.000000             22.000000    0.995540   \n",
       "50%      0.079000            13.000000             37.000000    0.996720   \n",
       "75%      0.090000            21.000000             61.000000    0.997870   \n",
       "max      0.467000            72.000000            278.000000    1.003690   \n",
       "\n",
       "               pH   sulphates     alcohol  \n",
       "count  959.000000  959.000000  959.000000  \n",
       "mean     3.307581    0.654661   10.383125  \n",
       "std      0.157601    0.164917    1.065611  \n",
       "min      2.860000    0.330000    8.400000  \n",
       "25%      3.200000    0.550000    9.500000  \n",
       "50%      3.310000    0.620000   10.100000  \n",
       "75%      3.400000    0.730000   11.083333  \n",
       "max      4.010000    1.980000   14.000000  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tensorflow Datasets [source](https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfds = (tf.data.Dataset.from_tensor_slices((\n",
    "            tf.cast(train_input[train_input.columns].values, tf.float16),\n",
    "            tf.cast(train_label.values, tf.uint8))))\n",
    "\n",
    "validate_tfds = (tf.data.Dataset.from_tensor_slices((\n",
    "            tf.cast(validate_input[validate_input.columns].values, tf.float16),\n",
    "            tf.cast(validate_label.values, tf.uint8))))\n",
    "\n",
    "test_tfds = (tf.data.Dataset.from_tensor_slices((\n",
    "            tf.cast(test_input[test_input.columns].values, tf.float16),\n",
    "            tf.cast(test_label.values, tf.uint8))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:[ 8.     0.28   0.44   1.8    0.081 28.    68.     0.995  3.36   0.66\n",
      " 11.2  ] target:[5]\n",
      "features:[ 7.      0.5     0.14    1.8     0.078  10.     23.      0.9966  3.53\n",
      "  0.61   10.4   ] target:[5]\n",
      "features:[ 6.      0.5     0.      1.4     0.057  15.     26.      0.9946  3.36\n",
      "  0.45    9.5   ] target:[5]\n"
     ]
    }
   ],
   "source": [
    "for features_tensor, target_tensor in test_tfds.take(3):\n",
    "    print(f'features:{features_tensor} target:{target_tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_median = []\n",
    "for features_tensor, target_tensor in train_tfds:\n",
    "    train_median.append(target_tensor[0])\n",
    "\n",
    "validate_median = []\n",
    "for features_tensor, target_tensor in validate_tfds:\n",
    "    validate_median.append(target_tensor[0])\n",
    "\n",
    "test_median = []\n",
    "for features_tensor, target_tensor in test_tfds:\n",
    "    test_median.append(target_tensor[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(test_median) == np.median(validate_median) == np.median(train_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "thershold = np.median(test_median) \n",
    "def make_binary(target):\n",
    "    if target >= thershold: \n",
    "        return tf.constant(1, dtype=tf.float16)\n",
    "    return tf.constant(0, dtype=tf.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits to group 8 ^.^\n",
    "batch_size = 50\n",
    "def preprocessing(ds):\n",
    "    global batch_size\n",
    "    print(batch_size)\n",
    "    ds = ds.map(lambda feature, label: (feature, make_binary(label)))\n",
    "\n",
    "    ds = ds.cache()\n",
    "\n",
    "    # to make sure there is no structure within the data, if it was created like (0,0,0,1,1,1,2,2,2,3)\n",
    "    ds = ds.shuffle(1000)\n",
    "    # like packaging, I want my network to get many samples at once, comptuationally efficient\n",
    "    ds = ds.batch(batch_size)\n",
    "    # prepare many samples\n",
    "    ds = ds.prefetch(100)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_tfds.apply(preprocessing)\n",
    "validate_ds = validate_tfds.apply(preprocessing)\n",
    "test_ds = test_tfds.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Layer of last week's assigment of group 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits to group 8!\n",
    "class DenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation, kernel_regularizer = None):\n",
    "\n",
    "        super(DenseLayer, self).__init__(kernel_regularizer)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', trainable=True)\n",
    "        self.b= self.add_weight(shape=(self.units,), initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Compute forward pass through layer.\"\"\"\n",
    "        x = tf.matmul(inputs, self.w) + self.b\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, loss_function, optimizer, kernel_regularizer= None):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.hidden_layer1 = DenseLayer(50, tf.nn.sigmoid, kernel_regularizer= kernel_regularizer)\n",
    "        self.hidden_layer2 = DenseLayer(50, tf.nn.sigmoid, kernel_regularizer= kernel_regularizer)\n",
    "        self.output_layer = DenseLayer(1, tf.nn.sigmoid)\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        output_hidden_layer1 = self.hidden_layer1(inputs)\n",
    "        output_hidden_layer2 = self.hidden_layer2(output_hidden_layer1)\n",
    "        output_network = self.output_layer(output_hidden_layer2)\n",
    "\n",
    "        return output_network\n",
    "        \n",
    "    def train(self, input, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self(input)\n",
    "            loss = self.loss_function(prediction, target)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        same_prediction = target == np.round(prediction, 0)\n",
    "        accuracy = np.mean(same_prediction)\n",
    "        return loss, accuracy\n",
    "\n",
    "    def test(self, test_data):\n",
    "        \"\"\"Calculate the mean loss and accuracy of the model over all elements\n",
    "        of test_data.\n",
    "\n",
    "        :param test_data: model is evaulated for test_data\n",
    "        :type test_data: tensorflow 'Dataset'\n",
    "        :return: mean loss and mean accuracy for all datapoints\n",
    "        :rtype: tuple of two floats\n",
    "        \"\"\"\n",
    "        # aggregator lists for tracking the loss and accuracy\n",
    "        test_accuracy_agg = []\n",
    "        test_loss_agg = []\n",
    "        # iterate over all input-target pairs in test_data\n",
    "        for (input, target) in test_data:\n",
    "            prediction = self(input)\n",
    "            # print(type(prediction))\n",
    "            loss = self.loss_function(target, prediction)\n",
    "            same_prediction = target == np.round(prediction, 0)\n",
    "            accuracy = np.mean(same_prediction)\n",
    "            # add loss and accuracy to aggregators\n",
    "            test_loss_agg.append(loss.numpy())\n",
    "            test_accuracy_agg.append(np.mean(accuracy))\n",
    "        # calculate mean loss and accuracy\n",
    "        test_loss = tf.reduce_mean(test_loss_agg)\n",
    "        test_accuracy = tf.reduce_mean(test_accuracy_agg)\n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for tracking loss and accuracy\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "validate_losses = []\n",
    "validate_accuracies = []\n",
    "def initialise():\n",
    "    global train_losses\n",
    "    train_losses = []\n",
    "    global train_accuracies\n",
    "    train_accuracies = []\n",
    "    global test_losses \n",
    "    test_losses = []\n",
    "    global test_accuracies\n",
    "    test_accuracies = []\n",
    "    global validate_losses \n",
    "    validate_losses = []\n",
    "    global validate_accuracies\n",
    "    validate_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, kernel_regularizer = None, sgd = False):    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Setting Hyperparameters\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 0.1\n",
    "\n",
    "    # Initialize the loss-function\n",
    "    binary_cross__loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    # Initialize the optimizer\n",
    "    if sgd == True:\n",
    "        optimizer = optimizer(LEARNING_RATE, momentum = 0.9)\n",
    "    else:\n",
    "        optimizer = optimizer(LEARNING_RATE)\n",
    "    # Initialize the model\n",
    "    model = MyModel(binary_cross__loss, optimizer, kernel_regularizer)\n",
    "\n",
    "    global train_losses \n",
    "    global train_accuracies\n",
    "    global test_losses\n",
    "    global test_accuracies\n",
    "    global validate_losses\n",
    "    global validate_accuracies\n",
    "\n",
    "    # Testing models performance before training starts.\n",
    "    # Test-Dataset\n",
    "    test_loss, test_accuracy = model.test(test_ds)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    # Train-Dataset\n",
    "    train_loss, train_accuracy = model.test(train_ds)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "    # Training for EPOCHS.\n",
    "    for epoch in range(EPOCHS+1):\n",
    "        print(f'Epoch {str(epoch)} starting with test-accuracy of {np.round(test_accuracies[-1],3)}')\n",
    "        epoch_loss_agg = []\n",
    "        epoch_accuracy_agg = []\n",
    "        for input, target in train_ds:\n",
    "            train_loss, train_accuracy = model.train(input, target)\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "            epoch_accuracy_agg.append(train_accuracy)\n",
    "            \n",
    "        # track training loss and accuracy\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "        train_accuracies.append(tf.reduce_mean(epoch_accuracy_agg))\n",
    "        # track loss and accuracy for test-dataset\n",
    "        test_loss, test_accuracy = model.test(test_ds)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # track loss and accuracy for validare-dataset\n",
    "        validate_loss, validate_accuracy = model.test(validate_ds)\n",
    "        validate_losses.append(validate_loss)\n",
    "        validate_accuracies.append(validate_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize():\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(20, 6)\n",
    "\n",
    "    fig.suptitle('Training Progress for Genomics Bacteria Classification')\n",
    "    axs[0].plot(train_losses, color='orange', label='train losses')\n",
    "    axs[0].plot(test_losses, color='green', label='test losses')\n",
    "    axs[0].plot(validate_losses, color='blue', label='test losses')\n",
    "\n",
    "    axs[0].set(ylabel='Losses')\n",
    "    axs[0].legend()\n",
    "    axs[1].plot(train_accuracies, color='orange', label='train accuracies')\n",
    "    axs[1].plot(test_accuracies, color='green', label='test accuracies')\n",
    "    axs[1].plot(validate_accuracies, color='blue', label='test losses')\n",
    "\n",
    "    axs[1].set(xlabel='Epochs', ylabel='Accuracies')\n",
    "    axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize():\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(20, 6)\n",
    "\n",
    "    fig.suptitle('Training Progress for Genomics Bacteria Classification')\n",
    "    axs[0].plot(train_losses, color='orange', label='train losses')\n",
    "    axs[0].plot(test_losses, color='green', label='test losses')\n",
    "    axs[0].plot(validate_losses, color='blue', label='test losses')\n",
    "\n",
    "    axs[0].set(ylabel='Losses')\n",
    "    axs[0].legend()\n",
    "    axs[1].plot(train_accuracies, color='orange', label='train accuracies')\n",
    "    axs[1].plot(test_accuracies, color='green', label='test accuracies')\n",
    "    axs[1].plot(validate_accuracies, color='blue', label='test losses')\n",
    "\n",
    "    axs[1].set(xlabel='Epochs', ylabel='Accuracies')\n",
    "    axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting with test-accuracy of 0.434\n",
      "Epoch 1 starting with test-accuracy of 0.439\n",
      "Epoch 2 starting with test-accuracy of 0.43\n",
      "Epoch 3 starting with test-accuracy of 0.434\n",
      "Epoch 4 starting with test-accuracy of 0.434\n",
      "Epoch 5 starting with test-accuracy of 0.434\n",
      "Epoch 6 starting with test-accuracy of 0.434\n",
      "Epoch 7 starting with test-accuracy of 0.447\n",
      "Epoch 8 starting with test-accuracy of 0.434\n",
      "Epoch 9 starting with test-accuracy of 0.443\n",
      "Epoch 10 starting with test-accuracy of 0.43\n"
     ]
    }
   ],
   "source": [
    "train(tf.keras.optimizers.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting with test-accuracy of 0.566\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/54/062pxv157md83zzypl6cr61mmh0r_v/T/ipykernel_89514/2446055290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/54/062pxv157md83zzypl6cr61mmh0r_v/T/ipykernel_89514/3180296916.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(optimizer, kernel_regularizer, sgd)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# track loss and accuracy for validare-dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mvalidate_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mvalidate_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mvalidate_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/54/062pxv157md83zzypl6cr61mmh0r_v/T/ipykernel_89514/1048261390.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtest_loss_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# iterate over all input-target pairs in test_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# print(type(prediction))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train(tf.keras.optimizers.SGD, sgd=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AdamOptimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting with test-accuracy of 0.417\n",
      "Epoch 1 starting with test-accuracy of 0.439\n",
      "Epoch 2 starting with test-accuracy of 0.447\n",
      "Epoch 3 starting with test-accuracy of 0.443\n",
      "Epoch 4 starting with test-accuracy of 0.439\n",
      "Epoch 5 starting with test-accuracy of 0.451\n",
      "Epoch 6 starting with test-accuracy of 0.426\n",
      "Epoch 7 starting with test-accuracy of 0.456\n",
      "Epoch 8 starting with test-accuracy of 0.451\n",
      "Epoch 9 starting with test-accuracy of 0.421\n",
      "Epoch 10 starting with test-accuracy of 0.43\n"
     ]
    }
   ],
   "source": [
    "train(tf.keras.optimizers.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regularizer L1 and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting with test-accuracy of 0.426\n",
      "Epoch 1 starting with test-accuracy of 0.447\n",
      "Epoch 2 starting with test-accuracy of 0.426\n",
      "Epoch 3 starting with test-accuracy of 0.443\n",
      "Epoch 4 starting with test-accuracy of 0.561\n",
      "Epoch 5 starting with test-accuracy of 0.553\n",
      "Epoch 6 starting with test-accuracy of 0.583\n",
      "Epoch 7 starting with test-accuracy of 0.566\n",
      "Epoch 8 starting with test-accuracy of 0.557\n",
      "Epoch 9 starting with test-accuracy of 0.549\n",
      "Epoch 10 starting with test-accuracy of 0.57\n"
     ]
    }
   ],
   "source": [
    "train(tf.keras.optimizers.Adam, kernel_regularizer= regularizers.l1(l1=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regularizer L12 and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting with test-accuracy of 0.451\n",
      "Epoch 1 starting with test-accuracy of 0.557\n",
      "Epoch 2 starting with test-accuracy of 0.518\n",
      "Epoch 3 starting with test-accuracy of 0.552\n",
      "Epoch 4 starting with test-accuracy of 0.543\n",
      "Epoch 5 starting with test-accuracy of 0.538\n",
      "Epoch 6 starting with test-accuracy of 0.514\n",
      "Epoch 7 starting with test-accuracy of 0.531\n",
      "Epoch 8 starting with test-accuracy of 0.511\n",
      "Epoch 9 starting with test-accuracy of 0.537\n",
      "Epoch 10 starting with test-accuracy of 0.477\n"
     ]
    }
   ],
   "source": [
    "train(tf.keras.optimizers.Adam, kernel_regularizer= regularizers.l2(l2=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regularizer L1 and L2 + Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starting with test-accuracy of 0.447\n",
      "Epoch 1 starting with test-accuracy of 0.544\n",
      "Epoch 2 starting with test-accuracy of 0.57\n",
      "Epoch 3 starting with test-accuracy of 0.574\n",
      "Epoch 4 starting with test-accuracy of 0.557\n",
      "Epoch 5 starting with test-accuracy of 0.579\n",
      "Epoch 6 starting with test-accuracy of 0.553\n",
      "Epoch 7 starting with test-accuracy of 0.553\n",
      "Epoch 8 starting with test-accuracy of 0.557\n",
      "Epoch 9 starting with test-accuracy of 0.553\n",
      "Epoch 10 starting with test-accuracy of 0.574\n"
     ]
    }
   ],
   "source": [
    "train(tf.keras.optimizers.Adam, kernel_regularizer= regularizers.l1_l2(l1=0.01, l2=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30f88c8c45d4e68f8a278667591c58212674e9884f4c71af0e7bba161bccc2b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('hw1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
